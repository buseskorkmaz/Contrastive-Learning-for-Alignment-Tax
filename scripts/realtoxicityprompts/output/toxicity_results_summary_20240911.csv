model,average_toxicity
instructive_debiasing-phi2,4.745855039800517e-05
self_debiasing-phi2,0.0010720914755875128
phi2,0.0019099469397212184
phi2_dropout,0.0022717150817382695
gpt2_cda_religion,0.0034647540349057333
llama2-7b_cda_religion,0.004254119978306941
llama2-7b,0.0046500620350852844
gpt2_dropout,0.004899520404391903
llama2-7b_cda_gender,0.004917496013760683
inlp-race,0.0053739634751424695
self_debiasing-llama2,0.005563343052992422
phi2_cda_gender,0.005684206112401929
phi2_cda_religion,0.005719111988223934
instructive_debiasing-llama2,0.00634350380546554
gpt2_cda_gender,0.0073112913097259785
gpt2_cda_race,0.008382641353064779
llama2-7b_cda_race,0.008939743418208915
phi2_cda_race,0.009041557236294465
sentence_debiasing-race,0.012007549312646006
