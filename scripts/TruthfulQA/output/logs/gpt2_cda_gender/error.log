/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:589: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 0!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 1!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 2!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 3!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 4!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 5!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 6!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 7!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 4-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 9!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 10!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 11!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 12!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 13!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 14!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 15!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 16!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 17!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 18!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 19!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 20!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 21!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 22!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 23!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 24!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 25!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 26!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 27!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 28!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 29!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 30!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 31!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 32!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 33!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 34!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 35!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 36!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 37!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 38!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 39!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 40!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 41!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 42!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 43!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 44!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 45!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 46!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 47!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 48!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 49!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 50!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 51!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 52!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 53!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 54!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 55!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 56!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 57!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 58!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 59!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 60!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 61!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 62!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 63!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 64!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 65!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 66!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 67!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 68!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 69!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 70!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 71!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 72!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 73!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 74!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 75!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 76!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 77!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 78!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 79!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 81!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 82!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 83!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 84!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 85!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 86!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 87!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 88!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 89!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 90!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 91!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 92!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 93!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 94!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 95!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 96!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 97!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 98!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 99!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 100!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 101!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 102!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 103!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 104!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 105!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 106!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 107!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 108!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 109!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 110!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 111!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 112!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 113!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 114!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 115!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 116!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 117!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 118!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 119!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 120!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 121!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 122!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 123!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 124!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 125!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 126!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 127!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 128!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 3-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 4-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 130!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 131!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 132!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 133!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 134!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 135!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 136!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 137!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 138!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 139!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 140!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 141!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 142!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 143!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 144!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 145!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 146!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 147!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 148!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 149!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 150!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 151!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 152!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 153!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 154!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 155!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 156!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 157!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 158!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 159!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 160!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 161!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 162!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 163!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 164!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 165!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 166!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 167!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 168!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 169!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 170!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 171!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 172!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 173!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 174!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 175!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 176!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 177!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 178!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 179!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 180!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 181!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 182!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 183!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 184!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 185!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 186!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 187!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 188!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 189!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 190!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 191!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 192!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 193!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 194!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 195!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 196!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 197!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 198!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 199!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 200!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 201!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 202!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 203!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 204!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 205!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 206!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 207!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 208!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 209!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 210!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 211!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 212!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 213!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 214!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 215!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 216!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 217!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 218!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 219!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 220!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 221!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 2-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 3-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 4-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 223!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 224!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 225!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 226!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 227!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 228!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 229!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 230!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 231!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 232!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 233!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 234!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 235!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 236!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 237!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 238!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 239!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 3-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 4-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 2-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 241!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 242!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 243!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 244!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 245!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 246!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 248!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 249!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 250!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 251!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 252!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 253!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 254!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 255!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 256!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 257!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 258!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 259!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 260!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 261!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 262!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 263!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 264!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 265!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 266!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 267!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 2-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 3-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 4-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 269!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 270!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 271!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 272!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 273!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 274!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 275!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 276!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 277!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 278!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 279!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 280!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 281!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 282!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 283!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 284!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 285!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 286!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 3-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 4-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 2-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 288!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 289!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 290!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 291!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 292!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 293!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 294!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 295!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 296!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 297!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 298!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 299!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 300!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 301!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 302!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 303!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 304!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 305!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 306!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 307!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 308!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 309!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 310!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 311!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 312!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 313!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 314!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 315!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 3-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 4-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 2-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 317!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 318!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 319!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 320!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 321!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 322!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 323!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 324!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 325!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 326!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 327!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 328!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 329!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 330!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 331!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 332!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 333!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 334!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 335!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 336!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 337!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 338!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 339!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 340!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 341!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 342!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 343!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 344!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 345!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 346!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 347!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 348!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 349!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 350!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 351!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 352!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 3-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 4-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 2-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 354!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 355!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 356!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 357!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 358!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 359!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 360!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 361!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 362!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 363!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 364!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 365!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 366!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 367!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 368!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 369!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 370!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 371!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 372!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 373!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 374!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 375!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 376!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 377!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 378!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 379!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 380!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 381!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 382!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 383!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 384!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 385!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 386!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 387!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 388!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 389!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 390!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 391!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 392!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 393!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 394!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 395!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 396!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 397!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 398!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 399!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 400!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 401!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 402!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 403!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 404!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 405!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 406!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 407!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 408!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 409!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 410!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 411!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 412!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 413!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 414!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 415!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 416!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 417!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 418!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 419!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 420!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 421!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 422!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 423!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 424!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 425!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 426!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 427!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 428!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 429!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 430!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 431!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 432!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 433!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 434!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 435!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 436!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 437!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 438!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 439!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 440!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 441!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 442!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 443!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 444!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 445!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 446!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 447!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 448!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 449!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 450!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 451!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 452!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 453!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 454!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 455!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 456!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 457!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 458!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 459!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 460!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 461!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 462!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 463!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 464!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 465!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 466!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 467!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 468!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 469!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 470!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 471!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 472!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 473!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 474!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 475!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 476!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 477!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 478!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 479!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 480!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 481!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 482!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 483!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 484!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 485!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 486!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 487!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 488!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 489!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 490!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 493!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 494!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 495!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 496!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 497!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 498!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 499!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 500!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 501!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 502!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 503!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 504!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 505!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 506!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 507!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 508!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 509!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 510!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 511!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 512!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 513!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 514!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 515!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 516!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 517!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 518!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 519!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 520!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 521!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 522!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 523!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 524!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 525!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 526!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 527!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 528!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 529!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 530!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 531!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 532!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 533!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 534!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 535!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 536!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 537!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 538!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 539!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 540!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 541!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 542!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 543!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 544!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 545!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 546!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 547!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 548!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 549!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 550!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 551!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 552!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 553!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 554!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 555!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 556!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 557!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 558!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 559!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 560!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 561!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 562!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 563!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 564!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 565!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 566!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 567!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 568!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 569!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 570!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 571!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 572!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 573!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 574!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 575!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 576!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 577!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 578!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 579!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 580!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 581!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 582!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 583!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 584!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 585!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 586!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 587!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 588!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 589!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 590!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 591!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 592!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 593!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 594!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 595!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 596!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 597!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 598!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 599!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 600!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 601!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 602!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 603!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 604!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 605!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 606!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 607!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 608!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 609!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 610!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 611!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 612!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 613!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 614!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 615!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 616!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 617!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 618!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 619!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 620!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 621!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 622!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 623!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 624!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 625!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 626!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 627!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 628!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 629!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 630!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 631!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 632!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 633!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 634!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 635!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 636!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 637!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 638!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 639!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 640!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 641!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 642!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 643!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 3-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 4-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 645!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 646!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 647!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 648!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 649!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 650!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 651!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 652!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 653!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 654!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 655!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 656!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 657!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 658!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 659!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 660!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 661!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 662!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 663!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 665!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 666!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 667!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 668!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 669!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 670!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 671!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 672!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 673!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 674!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 675!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 676!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 677!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 678!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 679!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 680!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 681!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 682!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 683!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 684!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 685!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 686!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 687!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 688!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 689!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 690!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 691!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 692!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 693!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 694!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 695!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 696!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 697!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 698!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 699!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 700!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 701!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 702!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 703!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 704!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 705!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 706!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 707!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 708!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 709!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 710!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 711!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 712!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 713!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 714!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 715!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 716!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 717!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 718!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 719!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 720!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 721!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 722!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 723!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 724!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 725!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 726!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 727!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 2-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 3-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 4-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 729!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 730!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 731!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 732!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 733!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 734!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 735!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 736!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 737!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 738!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 739!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 740!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 741!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 742!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 743!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 744!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 745!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 746!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 747!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 748!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 749!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 750!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 751!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 752!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 753!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 754!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 755!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 756!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 757!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 758!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 759!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 760!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 761!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 762!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 763!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 764!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 765!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 766!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 767!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 768!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 769!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 770!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 771!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 772!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 773!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 774!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 775!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 776!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 777!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 778!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 779!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 780!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 781!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 782!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 783!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 784!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 785!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 786!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 787!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 788!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 789!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 790!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 791!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 2-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 3-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/u/busekorkmaz/.conda/envs/fms_at_work/lib/python3.10/site-packages/nltk/translate/bleu_score.py:552: UserWarning: 
The hypothesis contains 0 counts of 4-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 793!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 794!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 795!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 796!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 797!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 798!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 799!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 800!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 801!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 802!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 803!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 804!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 805!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 806!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 807!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 808!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 809!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 810!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 811!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 812!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 813!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 814!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 815!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 816!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 0!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 1!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 2!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 3!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 4!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 5!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 6!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 7!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 9!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 10!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 11!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 12!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 13!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 14!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 15!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 16!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 17!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 18!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 19!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 20!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 21!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 22!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 23!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 24!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 25!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 26!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 27!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 28!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 29!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 30!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 31!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 32!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 33!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 34!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 35!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 36!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 37!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 38!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 39!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 40!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 41!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 42!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 43!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 44!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 45!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 46!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 47!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 48!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 49!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 50!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 51!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 52!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 53!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 54!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 55!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 56!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 57!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 58!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 59!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 60!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 61!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 62!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 63!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 64!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 65!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 66!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 67!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 68!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 69!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 70!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 71!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 72!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 73!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 74!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 75!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 76!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 77!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 78!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 79!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 81!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 82!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 83!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 84!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 85!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 86!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 87!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 88!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 89!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 90!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 91!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 92!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 93!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 94!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 95!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 96!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 97!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 98!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 99!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 100!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 101!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 102!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 103!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 104!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 105!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 106!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 107!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 108!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 109!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 110!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 111!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 112!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 113!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 114!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 115!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 116!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 117!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 118!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 119!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 120!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 121!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 122!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 123!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 124!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 125!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 126!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 127!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 128!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 130!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 131!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 132!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 133!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 134!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 135!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 136!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 137!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 138!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 139!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 140!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 141!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 142!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 143!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 144!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 145!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 146!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 147!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 148!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 149!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 150!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 151!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 152!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 153!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 154!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 155!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 156!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 157!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 158!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 159!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 160!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 161!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 162!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 163!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 164!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 165!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 166!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 167!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 168!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 169!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 170!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 171!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 172!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 173!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 174!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 175!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 176!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 177!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 178!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 179!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 180!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 181!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 182!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 183!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 184!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 185!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 186!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 187!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 188!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 189!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 190!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 191!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 192!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 193!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 194!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 195!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 196!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 197!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 198!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 199!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 200!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 201!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 202!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 203!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 204!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 205!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 206!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 207!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 208!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 209!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 210!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 211!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 212!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 213!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 214!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 215!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 216!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 217!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 218!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 219!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 220!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 221!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 223!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 224!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 225!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 226!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 227!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 228!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 229!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 230!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 231!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 232!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 233!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 234!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 235!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 236!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 237!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 238!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 239!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 241!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 242!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 243!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 244!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 245!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 246!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 248!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 249!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 250!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 251!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 252!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 253!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 254!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 255!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 256!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 257!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 258!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 259!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 260!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 261!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 262!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 263!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 264!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 265!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 266!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 267!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 269!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 270!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 271!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 272!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 273!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 274!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 275!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 276!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 277!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 278!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 279!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 280!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 281!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 282!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 283!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 284!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 285!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 286!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 288!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 289!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 290!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 291!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 292!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 293!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 294!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 295!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 296!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 297!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 298!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 299!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 300!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 301!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 302!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 303!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 304!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 305!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 306!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 307!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 308!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 309!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 310!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 311!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 312!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 313!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 314!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 315!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 317!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 318!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 319!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 320!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 321!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 322!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 323!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 324!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 325!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 326!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 327!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 328!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 329!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 330!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 331!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 332!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 333!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 334!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 335!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 336!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 337!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 338!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 339!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 340!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 341!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 342!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 343!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 344!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 345!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 346!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 347!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 348!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 349!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 350!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 351!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 352!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 354!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 355!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 356!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 357!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 358!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 359!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 360!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 361!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 362!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 363!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 364!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 365!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 366!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 367!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 368!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 369!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 370!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 371!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 372!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 373!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 374!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 375!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 376!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 377!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 378!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 379!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 380!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 381!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 382!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 383!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 384!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 385!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 386!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 387!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 388!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 389!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 390!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 391!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 392!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 393!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 394!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 395!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 396!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 397!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 398!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 399!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 400!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 401!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 402!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 403!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 404!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 405!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 406!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 407!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 408!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 409!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 410!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 411!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 412!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 413!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 414!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 415!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 416!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 417!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 418!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 419!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 420!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 421!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 422!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 423!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 424!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 425!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 426!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 427!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 428!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 429!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 430!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 431!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 432!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 433!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 434!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 435!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 436!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 437!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 438!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 439!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 440!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 441!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 442!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 443!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 444!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 445!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 446!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 447!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 448!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 449!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 450!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 451!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 452!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 453!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 454!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 455!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 456!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 457!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 458!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 459!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 460!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 461!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 462!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 463!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 464!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 465!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 466!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 467!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 468!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 469!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 470!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 471!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 472!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 473!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 474!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 475!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 476!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 477!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 478!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 479!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 480!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 481!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 482!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 483!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 484!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 485!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 486!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 487!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 488!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 489!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 490!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 493!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 494!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 495!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 496!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 497!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 498!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 499!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 500!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 501!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 502!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 503!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 504!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 505!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 506!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 507!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 508!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 509!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 510!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 511!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 512!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 513!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 514!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 515!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 516!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 517!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 518!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 519!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 520!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 521!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 522!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 523!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 524!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 525!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 526!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 527!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 528!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 529!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 530!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 531!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 532!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 533!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 534!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 535!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 536!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 537!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 538!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 539!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 540!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 541!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 542!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 543!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 544!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 545!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 546!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 547!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 548!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 549!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 550!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 551!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 552!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 553!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 554!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 555!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 556!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 557!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 558!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 559!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 560!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 561!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 562!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 563!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 564!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 565!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 566!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 567!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 568!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 569!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 570!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 571!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 572!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 573!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 574!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 575!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 576!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 577!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 578!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 579!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 580!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 581!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 582!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 583!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 584!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 585!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 586!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 587!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 588!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 589!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 590!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 591!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 592!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 593!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 594!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 595!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 596!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 597!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 598!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 599!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 600!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 601!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 602!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 603!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 604!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 605!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 606!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 607!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 608!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 609!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 610!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 611!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 612!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 613!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 614!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 615!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 616!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 617!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 618!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 619!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 620!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 621!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 622!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 623!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 624!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 625!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 626!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 627!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 628!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 629!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 630!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 631!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 632!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 633!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 634!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 635!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 636!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 637!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 638!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 639!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 640!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 641!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 642!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 643!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 645!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 646!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 647!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 648!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 649!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 650!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 651!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 652!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 653!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 654!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 655!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 656!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 657!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 658!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 659!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 660!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 661!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 662!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 663!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 665!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 666!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 667!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 668!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 669!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 670!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 671!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 672!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 673!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 674!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 675!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 676!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 677!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 678!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 679!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 680!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 681!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 682!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 683!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 684!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 685!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 686!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 687!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 688!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 689!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 690!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 691!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 692!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 693!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 694!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 695!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 696!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 697!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 698!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 699!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 700!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 701!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 702!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 703!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 704!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 705!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 706!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 707!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 708!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 709!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 710!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 711!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 712!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 713!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 714!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 715!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 716!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 717!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 718!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 719!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 720!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 721!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 722!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 723!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 724!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 725!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 726!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 727!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 729!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 730!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 731!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 732!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 733!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 734!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 735!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 736!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 737!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 738!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 739!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 740!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 741!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 742!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 743!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 744!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 745!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 746!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 747!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 748!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 749!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 750!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 751!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 752!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 753!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 754!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 755!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 756!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 757!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 758!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 759!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 760!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 761!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 762!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 763!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 764!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 765!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 766!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 767!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 768!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 769!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 770!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 771!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 772!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 773!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 774!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 775!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 776!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 777!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 778!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 779!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 780!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 781!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 782!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 783!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 784!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 785!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 786!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 787!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 788!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 789!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 790!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:140: UserWarning: Answers missing for gpt2_cda_gender 791!
  questions = metrics.run_bleu_and_rouge(model_key, questions)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|     | 1/2 [02:21<02:21, 141.79s/it]Loading checkpoint shards: 100%|| 2/2 [03:03<00:00, 82.65s/it] Loading checkpoint shards: 100%|| 2/2 [03:03<00:00, 91.52s/it]
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 0!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 1!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 2!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 3!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 4!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 5!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 6!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 7!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 9!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 10!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 11!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 12!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 13!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 14!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 15!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 16!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 17!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 18!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 19!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 20!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 21!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 22!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 23!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 24!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 25!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 26!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 27!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 28!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 29!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 30!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 31!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 32!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 33!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 34!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 35!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 36!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 37!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 38!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 39!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 40!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 41!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 42!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 43!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 44!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 45!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 46!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 47!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 48!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 49!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 50!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 51!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 52!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 53!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 54!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 55!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 56!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 57!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 58!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 59!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 60!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 61!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 62!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 63!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 64!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 65!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 66!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 67!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 68!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 69!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 70!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 71!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 72!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 73!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 74!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 75!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 76!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 77!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 78!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 79!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 81!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 82!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 83!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 84!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 85!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 86!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 87!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 88!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 89!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 90!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 91!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 92!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 93!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 94!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 95!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 96!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 97!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 98!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 99!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 100!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 101!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 102!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 103!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 104!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 105!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 106!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 107!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 108!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 109!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 110!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 111!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 112!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 113!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 114!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 115!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 116!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 117!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 118!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 119!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 120!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 121!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 122!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 123!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 124!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 125!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 126!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 127!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 128!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 130!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 131!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 132!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 133!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 134!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 135!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 136!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 137!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 138!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 139!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 140!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 141!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 142!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 143!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 144!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 145!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 146!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 147!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 148!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 149!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 150!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 151!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 152!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 153!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 154!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 155!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 156!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 157!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 158!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 159!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 160!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 161!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 162!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 163!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 164!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 165!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 166!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 167!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 168!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 169!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 170!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 171!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 172!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 173!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 174!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 175!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 176!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 177!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 178!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 179!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 180!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 181!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 182!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 183!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 184!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 185!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 186!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 187!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 188!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 189!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 190!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 191!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 192!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 193!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 194!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 195!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 196!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 197!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 198!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 199!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 200!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 201!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 202!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 203!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 204!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 205!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 206!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 207!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 208!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 209!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 210!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 211!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 212!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 213!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 214!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 215!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 216!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 217!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 218!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 219!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 220!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 221!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 223!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 224!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 225!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 226!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 227!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 228!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 229!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 230!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 231!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 232!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 233!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 234!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 235!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 236!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 237!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 238!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 239!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 241!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 242!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 243!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 244!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 245!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 246!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 248!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 249!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 250!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 251!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 252!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 253!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 254!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 255!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 256!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 257!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 258!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 259!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 260!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 261!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 262!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 263!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 264!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 265!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 266!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 267!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 269!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 270!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 271!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 272!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 273!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 274!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 275!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 276!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 277!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 278!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 279!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 280!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 281!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 282!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 283!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 284!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 285!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 286!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 288!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 289!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 290!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 291!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 292!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 293!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 294!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 295!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 296!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 297!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 298!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 299!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 300!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 301!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 302!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 303!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 304!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 305!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 306!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 307!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 308!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 309!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 310!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 311!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 312!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 313!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 314!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 315!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 317!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 318!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 319!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 320!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 321!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 322!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 323!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 324!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 325!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 326!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 327!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 328!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 329!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 330!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 331!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 332!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 333!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 334!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 335!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 336!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 337!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 338!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 339!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 340!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 341!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 342!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 343!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 344!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 345!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 346!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 347!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 348!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 349!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 350!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 351!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 352!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 354!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 355!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 356!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 357!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 358!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 359!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 360!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 361!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 362!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 363!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 364!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 365!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 366!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 367!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 368!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 369!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 370!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 371!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 372!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 373!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 374!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 375!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 376!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 377!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 378!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 379!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 380!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 381!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 382!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 383!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 384!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 385!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 386!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 387!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 388!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 389!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 390!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 391!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 392!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 393!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 394!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 395!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 396!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 397!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 398!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 399!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 400!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 401!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 402!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 403!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 404!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 405!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 406!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 407!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 408!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 409!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 410!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 411!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 412!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 413!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 414!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 415!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 416!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 417!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 418!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 419!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 420!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 421!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 422!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 423!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 424!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 425!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 426!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 427!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 428!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 429!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 430!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 431!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 432!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 433!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 434!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 435!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 436!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 437!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 438!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 439!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 440!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 441!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 442!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 443!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 444!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 445!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 446!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 447!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 448!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 449!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 450!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 451!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 452!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 453!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 454!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 455!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 456!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 457!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 458!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 459!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 460!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 461!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 462!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 463!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 464!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 465!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 466!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 467!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 468!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 469!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 470!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 471!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 472!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 473!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 474!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 475!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 476!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 477!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 478!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 479!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 480!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 481!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 482!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 483!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 484!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 485!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 486!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 487!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 488!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 489!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 490!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 493!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 494!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 495!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 496!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 497!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 498!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 499!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 500!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 501!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 502!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 503!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 504!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 505!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 506!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 507!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 508!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 509!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 510!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 511!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 512!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 513!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 514!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 515!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 516!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 517!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 518!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 519!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 520!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 521!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 522!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 523!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 524!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 525!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 526!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 527!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 528!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 529!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 530!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 531!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 532!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 533!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 534!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 535!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 536!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 537!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 538!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 539!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 540!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 541!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 542!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 543!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 544!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 545!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 546!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 547!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 548!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 549!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 550!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 551!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 552!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 553!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 554!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 555!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 556!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 557!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 558!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 559!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 560!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 561!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 562!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 563!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 564!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 565!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 566!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 567!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 568!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 569!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 570!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 571!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 572!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 573!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 574!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 575!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 576!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 577!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 578!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 579!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 580!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 581!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 582!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 583!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 584!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 585!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 586!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 587!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 588!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 589!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 590!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 591!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 592!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 593!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 594!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 595!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 596!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 597!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 598!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 599!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 600!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 601!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 602!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 603!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 604!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 605!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 606!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 607!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 608!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 609!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 610!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 611!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 612!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 613!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 614!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 615!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 616!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 617!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 618!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 619!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 620!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 621!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 622!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 623!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 624!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 625!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 626!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 627!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 628!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 629!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 630!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 631!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 632!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 633!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 634!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 635!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 636!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 637!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 638!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 639!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 640!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 641!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 642!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 643!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 645!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 646!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 647!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 648!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 649!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 650!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 651!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 652!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 653!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 654!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 655!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 656!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 657!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 658!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 659!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 660!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 661!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 662!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 663!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 665!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 666!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 667!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 668!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 669!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 670!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 671!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 672!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 673!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 674!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 675!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 676!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 677!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 678!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 679!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 680!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 681!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 682!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 683!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 684!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 685!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 686!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 687!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 688!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 689!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 690!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 691!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 692!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 693!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 694!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 695!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 696!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 697!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 698!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 699!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 700!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 701!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 702!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 703!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 704!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 705!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 706!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 707!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 708!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 709!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 710!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 711!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 712!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 713!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 714!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 715!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 716!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 717!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 718!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 719!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 720!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 721!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 722!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 723!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 724!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 725!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 726!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 727!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 729!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 730!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 731!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 732!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 733!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 734!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 735!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 736!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 737!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 738!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 739!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 740!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 741!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 742!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 743!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 744!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 745!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 746!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 747!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 748!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 749!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 750!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 751!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 752!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 753!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 754!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 755!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 756!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 757!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 758!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 759!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 760!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 761!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 762!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 763!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 764!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 765!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 766!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 767!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 768!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 769!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 770!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 771!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 772!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 773!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 774!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 775!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 776!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 777!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 778!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 779!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 780!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 781!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 782!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 783!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 784!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 785!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 786!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 787!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 788!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 789!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 790!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 791!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 793!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 794!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 795!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 796!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 797!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 798!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 799!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 800!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 801!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 802!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 803!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 804!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 805!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 806!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 807!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 808!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 809!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 810!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 811!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 812!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 813!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 814!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 815!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 816!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|     | 1/2 [01:44<01:44, 104.98s/it]Loading checkpoint shards: 100%|| 2/2 [02:32<00:00, 71.05s/it] Loading checkpoint shards: 100%|| 2/2 [02:32<00:00, 76.14s/it]
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 0!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 1!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 2!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 3!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 4!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 5!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 6!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 7!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 9!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 10!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 11!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 12!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 13!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 14!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 15!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 16!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 17!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 18!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 19!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 20!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 21!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 22!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 23!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 24!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 25!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 26!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 27!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 28!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 29!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 30!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 31!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 32!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 33!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 34!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 35!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 36!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 37!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 38!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 39!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 40!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 41!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 42!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 43!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 44!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 45!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 46!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 47!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 48!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 49!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 50!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 51!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 52!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 53!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 54!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 55!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 56!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 57!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 58!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 59!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 60!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 61!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 62!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 63!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 64!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 65!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 66!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 67!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 68!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 69!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 70!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 71!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 72!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 73!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 74!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 75!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 76!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 77!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 78!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 79!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 81!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 82!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 83!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 84!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 85!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 86!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 87!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 88!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 89!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 90!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 91!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 92!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 93!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 94!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 95!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 96!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 97!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 98!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 99!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 100!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 101!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 102!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 103!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 104!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 105!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 106!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 107!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 108!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 109!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 110!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 111!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 112!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 113!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 114!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 115!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 116!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 117!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 118!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 119!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 120!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 121!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 122!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 123!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 124!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 125!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 126!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 127!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 128!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 130!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 131!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 132!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 133!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 134!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 135!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 136!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 137!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 138!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 139!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 140!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 141!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 142!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 143!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 144!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 145!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 146!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 147!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 148!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 149!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 150!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 151!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 152!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 153!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 154!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 155!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 156!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 157!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 158!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 159!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 160!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 161!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 162!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 163!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 164!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 165!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 166!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 167!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 168!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 169!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 170!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 171!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 172!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 173!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 174!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 175!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 176!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 177!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 178!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 179!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 180!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 181!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 182!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 183!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 184!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 185!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 186!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 187!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 188!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 189!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 190!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 191!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 192!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 193!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 194!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 195!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 196!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 197!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 198!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 199!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 200!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 201!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 202!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 203!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 204!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 205!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 206!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 207!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 208!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 209!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 210!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 211!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 212!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 213!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 214!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 215!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 216!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 217!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 218!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 219!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 220!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 221!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 223!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 224!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 225!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 226!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 227!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 228!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 229!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 230!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 231!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 232!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 233!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 234!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 235!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 236!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 237!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 238!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 239!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 241!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 242!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 243!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 244!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 245!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 246!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 248!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 249!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 250!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 251!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 252!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 253!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 254!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 255!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 256!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 257!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 258!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 259!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 260!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 261!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 262!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 263!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 264!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 265!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 266!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 267!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 269!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 270!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 271!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 272!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 273!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 274!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 275!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 276!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 277!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 278!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 279!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 280!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 281!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 282!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 283!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 284!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 285!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 286!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 288!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 289!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 290!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 291!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 292!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 293!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 294!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 295!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 296!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 297!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 298!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 299!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 300!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 301!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 302!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 303!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 304!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 305!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 306!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 307!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 308!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 309!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 310!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 311!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 312!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 313!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 314!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 315!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 317!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 318!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 319!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 320!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 321!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 322!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 323!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 324!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 325!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 326!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 327!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 328!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 329!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 330!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 331!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 332!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 333!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 334!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 335!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 336!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 337!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 338!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 339!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 340!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 341!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 342!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 343!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 344!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 345!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 346!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 347!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 348!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 349!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 350!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 351!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 352!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 354!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 355!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 356!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 357!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 358!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 359!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 360!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 361!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 362!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 363!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 364!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 365!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 366!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 367!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 368!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 369!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 370!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 371!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 372!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 373!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 374!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 375!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 376!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 377!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 378!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 379!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 380!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 381!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 382!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 383!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 384!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 385!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 386!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 387!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 388!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 389!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 390!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 391!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 392!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 393!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 394!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 395!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 396!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 397!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 398!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 399!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 400!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 401!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 402!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 403!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 404!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 405!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 406!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 407!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 408!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 409!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 410!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 411!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 412!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 413!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 414!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 415!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 416!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 417!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 418!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 419!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 420!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 421!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 422!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 423!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 424!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 425!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 426!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 427!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 428!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 429!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 430!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 431!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 432!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 433!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 434!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 435!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 436!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 437!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 438!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 439!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 440!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 441!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 442!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 443!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 444!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 445!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 446!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 447!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 448!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 449!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 450!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 451!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 452!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 453!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 454!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 455!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 456!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 457!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 458!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 459!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 460!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 461!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 462!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 463!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 464!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 465!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 466!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 467!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 468!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 469!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 470!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 471!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 472!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 473!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 474!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 475!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 476!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 477!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 478!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 479!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 480!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 481!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 482!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 483!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 484!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 485!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 486!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 487!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 488!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 489!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 490!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 493!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 494!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 495!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 496!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 497!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 498!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 499!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 500!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 501!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 502!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 503!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 504!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 505!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 506!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 507!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 508!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 509!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 510!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 511!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 512!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 513!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 514!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 515!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 516!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 517!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 518!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 519!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 520!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 521!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 522!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 523!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 524!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 525!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 526!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 527!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 528!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 529!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 530!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 531!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 532!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 533!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 534!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 535!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 536!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 537!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 538!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 539!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 540!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 541!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 542!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 543!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 544!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 545!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 546!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 547!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 548!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 549!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 550!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 551!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 552!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 553!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 554!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 555!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 556!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 557!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 558!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 559!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 560!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 561!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 562!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 563!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 564!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 565!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 566!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 567!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 568!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 569!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 570!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 571!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 572!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 573!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 574!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 575!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 576!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 577!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 578!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 579!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 580!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 581!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 582!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 583!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 584!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 585!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 586!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 587!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 588!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 589!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 590!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 591!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 592!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 593!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 594!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 595!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 596!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 597!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 598!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 599!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 600!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 601!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 602!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 603!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 604!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 605!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 606!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 607!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 608!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 609!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 610!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 611!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 612!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 613!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 614!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 615!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 616!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 617!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 618!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 619!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 620!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 621!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 622!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 623!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 624!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 625!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 626!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 627!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 628!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 629!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 630!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 631!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 632!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 633!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 634!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 635!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 636!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 637!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 638!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 639!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 640!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 641!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 642!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 643!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 645!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 646!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 647!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 648!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 649!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 650!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 651!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 652!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 653!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 654!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 655!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 656!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 657!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 658!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 659!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 660!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 661!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 662!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 663!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 665!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 666!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 667!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 668!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 669!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 670!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 671!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 672!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 673!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 674!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 675!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 676!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 677!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 678!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 679!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 680!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 681!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 682!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 683!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 684!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 685!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 686!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 687!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 688!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 689!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 690!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 691!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 692!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 693!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 694!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 695!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 696!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 697!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 698!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 699!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 700!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 701!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 702!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 703!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 704!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 705!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 706!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 707!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 708!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 709!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 710!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 711!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 712!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 713!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 714!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 715!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 716!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 717!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 718!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 719!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 720!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 721!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 722!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 723!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 724!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 725!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 726!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 727!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 729!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 730!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 731!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 732!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 733!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 734!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 735!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 736!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 737!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 738!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 739!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 740!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 741!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 742!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 743!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 744!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 745!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 746!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 747!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 748!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 749!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 750!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 751!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 752!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 753!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 754!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 755!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 756!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 757!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 758!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 759!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 760!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 761!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 762!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 763!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 764!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 765!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 766!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 767!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 768!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 769!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 770!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 771!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 772!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 773!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 774!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 775!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 776!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 777!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 778!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 779!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 780!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 781!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 782!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 783!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 784!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 785!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 786!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 787!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 788!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 789!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 790!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 791!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 793!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 794!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 795!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 796!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 797!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 798!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 799!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 800!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 801!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 802!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 803!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 804!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 805!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 806!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 807!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 808!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 809!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 810!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 811!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 812!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 813!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 814!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 815!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
/dccstor/autofair/busekorkmaz/factual-bias-mitigation/scripts/TruthfulQA/truthfulqa/evaluate.py:158: UserWarning: Answer missing for gpt2_cda_gender 816!
  questions = metrics.run_end2end_llama(model_key, metric, questions, device=torch_device, cache_dir=args.cache_dir)
