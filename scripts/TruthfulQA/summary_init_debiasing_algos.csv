Model,BLEURT acc,Llama-info,Llama-judge,MC1,MC2,bleu acc,rouge1 acc
gpt2,0.35128518971848227,0.6878824969400245,0.3537331701346389,0.22766217870257038,0.4075183416144278,0.26438188494492043,0.3072215422276622
inlp-gender,0.3762254901960784,0.6274509803921569,0.43014705882352944,0.22031823745410037,0.41985989483050146,0.23651960784313725,0.2916666666666667
inlp-race,,0.5355392156862745,0.46691176470588236,0.23623011015911874,0.42259579255233937,0.2647058823529412,0.31495098039215685
instructive_debiasing,0.3378212974296206,0.6842105263157895,0.3733170134638923,0.22643818849449204,0.4055311068426973,0.2827417380660955,0.3023255813953488
self_debiasing,0.35128518971848227,0.6878824969400245,0.3537331701346389,0.22766217870257038,0.4075183416144278,0.26438188494492043,0.3072215422276622
sentence_debiasing-gender,0.6711656441717792,0.14846625766871166,0.5680981595092025,0.23745410036719705,0.46110343165004075,0.1460122699386503,0.20613496932515338
sentence_debiasing-race,,0.49291784702549574,0.5538243626062322,0.23133414932680538,0.4145480982113177,0.2847025495750708,0.3640226628895184
gpt2_cda_gender,,0.5625,0.5,0.2252141982864137,0.4178164010385628,0.1875,0.3125
gpt2_cda_religion,,0.6808035714285714,0.35044642857142855,0.23133414932680538,0.4101115167953214,0.24776785714285715,0.28125
gpt2_cda_race,,0.6795096322241682,0.3432574430823117,0.22888616891064872,0.40963381114223724,0.25569176882662,0.2732049036777583
gpt2_dropout,,0.6638036809815951,0.3202453987730061,0.2350061199510404,0.4196469708082884,0.2625766871165644,0.3067484662576687
llama2-7b,,0.9975520195838433,0.8041615667074663,0.24724602203182375,0.3876366610144567,0.32313341493268055,0.35128518971848227
llama2-7b_cda_gender,,0.9840881272949816,0.7552019583843329,0.24479804161566707,0.38224541049454897,0.3108935128518972,0.33659730722154224
llama2-7b_cda_race,,0.9730722154222766,0.3953488372093023,0.24357405140758873,0.3766591246314585,0.3011015911872705,0.3072215422276622
llama2-7b_cda_religion,,0.9620563035495716,0.4394124847001224,0.25458996328029376,0.38800784365093444,0.30354957160342716,0.30354957160342716
llama2-7b_dropout,,0.9280397022332506,0.7866004962779156,0.2582619339045288,0.3940964315392819,0.3076923076923077,0.3250620347394541
phi2,,0.9522643818849449,0.42962056303549573,0.31211750305997554,0.4456044914049201,0.3769889840881273,0.3880048959608323
phi2_cda_religion,,0.9838509316770186,0.3341614906832298,0.27906976744186046,0.3904942014049773,0.2894409937888199,0.3142857142857143
phi2_cda_gender,,0.9839307787391842,0.37453646477132263,0.28886168910648713,0.41318087152835703,0.3263288009888752,0.34981458590852904
phi2_dropout,,0.9779411764705882,0.40441176470588236,0.2998776009791922,0.4269058673788354,0.3480392156862745,0.3762254901960784